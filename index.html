<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Introduction to In-Context Learning - Hsiang Fu, Heni Ben Amor">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Hsiang Fu, Heni Ben Amor">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Interactive Robotics Lab, Arizona State University">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Introduction to In-Context Learning">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Introduction to In-Context Learning (ASU IRL)</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "Hsiang Fu",
        "affiliation": {
          "@type": "Interactive Robotics Lab",
          "name": "Arizona State University"
        }
      },
      {
        "@type": "Person",
        "name": "Heni Ben Amor",
        "affiliation": {
          "@type": "Interactive Robotics Lab",
          "name": "Arizona State University"
        }
      }
    ]

    "datePublished": "2025-10-31",
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Introduction to In-Context Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/hsiangfu" target="_blank">Hsiang Fu</a>,</span>
                <span class="author-block">
                  <a href="https://henibenamor.weebly.com/" target="_blank">Heni Ben Amor</a></span>
                  </div>
                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">Interactive Robotics Lab<br>Arizona State University</span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://github.com/hsiang-fu/icl_demos" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="https://drive.google.com/drive/folders/1NFf7mnk8v5Z3A2JeIBdeNt-ifKLDQEXW?usp=sharing" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-google-drive"></i>
                      </span>
                      <span>Demos</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span> -->
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://interactive-robotics.engineering.asu.edu/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-flask"></i>
                  </span>
                  <span>Lab</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            In-Context Learning (ICL) enables large language models (LLMs) to adapt their behavior and perform new tasks without updating their internal parameters, such as weights and biases. Instead of retraining or reprogramming the model with large datasets, ICL allows it to learn “on the fly” by using examples, instructions, or demonstrations provided in the input. This approach leverages the model’s pretrained knowledge to complete new tasks simply by showing examples of how those tasks should be performed. LLMs can recognize and complete abstract patterns by observing input-output examples and can even extrapolate functions from these sequences, demonstrating their ability to generalize through pattern learning rather than parameter updates (Mirchandani et al.).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper Overview -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            This introduction will present a series of interactive demos that showcase how In-Context Learning (ICL) can be applied to sequence prediction, sequence transformation, _____, and _______. Each demo illustrates how large language models (specifically Google Gemini’s models) can infer rules, patterns, or relationships directly from zero-shot, few-shot, or many shot examples—without explicit retraining or fine-tuning.
          </p>
          <p>
            In the <strong>sequence prediction</strong> demos, the model learns to anticipate the next element in a pattern based on preceding examples, such as predicting numerical progressions in sine functions with transformations, or predicting time-based trends such as blood sugar levels throughout the data. 
          </p>
          <p>
            The <strong>sequence transformation</strong> demo highlight the model’s ability to map one sequence to another—for instance, converting input patterns into structured output patterns, translating formats, or filling in blanks of input patterns to match trends found in other patterns.
          </p>
          <p>
            # add more tasks + descriptions
          </p>
          <p>
            Together, these demonstrations emphasize the adaptability and reasoning capabilities of modern language models. By observing only a handful of examples, they can internalize task logic and apply it to new, unseen data—mimicking human learning from context.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper Overview -->

<!-- Paper Demos -->
<section class="section hero is-light">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Demos</h2>
    <div class="columns is-multiline is-variable is-6" style="align-items: stretch;">
      
      <!-- Left Column -->
      <div class="column is-half">
        <div class="box has-text-justified" style="height: 100%;">
          <h3 class="title is-4">Sequence Prediction</h3>
          <p>
            In this demo, we utilized a collection of numerical sequences derived from transformations of the sine function as the “training” examples for the Large Language Model (LLM). For the function a⋅x⋅sin(bx), the model was provided with 10 example sequences generated from uniformly sampled x-values within the range [0, 2π], capturing one complete periodic cycle of the sine wave. 
          </p>
          <br>
          <p>
            For the function a⋅sin(bx), we also used a similar collection of numerical sequences generated from transformations of the sine function as training examples for the LLM. In this case, the model was given 5 example sequences created from uniformly sampled x-values in the range [0, 2π], representing one full cycle of the sine wave. 
          </p>
          <br>
          <p>
            Lastly for both functions, the sequences were then input into the <strong>Gemini 2.5-Flash</strong> model, with reasoning mode turned off to focus on direct pattern continuation rather than higher-level inference. In addition to the training examples, a user-defined test sequence extending beyond the 2π interval was provided to assess the model’s ability to extrapolate and maintain the periodic characteristics of the sine function. Finally, the model was prompted to generate 50, 100, or 200 additional values for each test sequence, demonstrating its capacity to recognize, generalize, and extend the learned sinusoidal patterns.
          </p>
          <br>
          <h3 class="title is-4">Prompt Example</h3>
<pre style="white-space: pre-wrap; word-wrap: break-word;">
  <code>You are given several example sequences of (x, y) pairs generated by different mathematical patterns.

Example 1: [(0.0, 0.0), (0.025, 0.199), (0.05, 0.389), ...]
Example 2: [(0.0, 0.0), (0.025, 0.397), (0.05, 0.779), ...]
Example 3: [(0.0, 0.0), (0.025, 0.596), (0.05, 1.168), ...]
Example 4: [(0.0, 0.0), (0.025, 0.795), (0.05, 1.558), ...]
Example 5: [(0.0, 0.0), (0.025, 0.993), (0.05, 1.947), ...]
Example 6: [(0.0, 0.0), (0.025, 1.192), (0.05, 2.337), ...]
...

The following sequence represents a partial test input: {test}

Now generate the next 200 new (x, y) pairs that follow the same underlying mathematical pattern, continuing naturally from where the test sequence ends.

Output a  Python list of [x, y] pairs in this format, remember to close all brackets correctly:
[(x1, y1), (x2, y2), (x3, y3), (x4, y4), (x5, y5), ...]
No explanations, no code, no comments — only the list.
</code>
</pre>
        </div>
      </div>

      <!-- Right Column -->
      <div class="column is-half">
        <div class="box has-text-justified" style="height: 100%;">
          <h3 class="title is-4">Example</h3>
            <img src="static/images/sequence_completion_axsin(bx).gif" alt="a⋅x⋅sin(bx)">
              <p>
              For the function <strong>a⋅x⋅sin(bx)</strong>, the model is given initial examples (gray curve) — representing the known part of the sequence — and is then asked to make predictions of the pattern (red curve) beyond the known range of the sequence. The dashed gray curve serves as the ground truth of the sequence. 
              </p>
            <br>
            <img src="static/images/sequence_completion_asin(bx).gif" alt="a⋅sin(bx)">
              <p>
              For the function <strong>a⋅sin(bx)</strong>, the model is given initial examples (gray curve) — representing the known part of the sequence — and is then asked to make predictions of the pattern (red curve) beyond the known range of the sequence. The dashed gray curve serves as the ground truth of the sequence. 
              </p>
            <br>
              <p>
              By adjusting the amplitude and frequency parameters in the demo, you can explore how LLMs understand the underlying mathematical relationship and predict future values based on the provided examples.
              </p>
            <br>
              <div align="center">
              <a href="https://colab.research.google.com/drive/1GSsmx1Ms5-RnfafRm6qGohgaVgyrSi0W?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fa fa-file"></i>
                </span>
                <span>Try the Demo Here @ Google Colab</span>
              </a>
            </div>
        </div>
      </div>

      <!-- Left Column -->
      <div class="column is-half">
        <div class="box has-text-justified" style="height: 100%;">
          <h3 class="title is-4">Glucose Level Prediction</h3>
          <p>
            Description or content for the first demo goes here. This could include text, links, or images.
          </p>
        </div>
      </div>

      <!-- Right Column -->
      <div class="column is-half">
        <div class="box has-text-justified" style="height: 100%;">
          <h3 class="title is-4">Example</h3>
            <p>
            Description or content for the second demo goes here. You can also include buttons or media.
            </p>
            <div align="center">
              <a href="https://colab.research.google.com/drive/1buA3TM0VWCR_8x3KT0ZzQnt0uEt3poIa?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fa fa-file"></i>
                </span>
                <span>Try the Demo Here</span>
              </a>
            </div>
          
        </div>
      </div>

      <div class="column is-half">
        <div class="box has-text-justified" style="height: 100%;">
          <h3 class="title is-4">Seqeunce Transformation</h3>
          <p>
            Description or content for the first demo goes here. This could include text, links, or images.
          </p>
        </div>
      </div>

      <!-- Right Column -->
      <div class="column is-half">
        <div class="box has-text-justified" style="height: 100%;">
          <h3 class="title is-4">Example</h3>
            <p>
            Description or content for the second demo goes here. You can also include buttons or media.
            </p>
            <div align="center">
              <a href="https://colab.research.google.com/drive/1buA3TM0VWCR_8x3KT0ZzQnt0uEt3poIa?usp=sharing" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fa fa-file"></i>
                </span>
                <span>Try the Demo Here</span>
              </a>
            </div>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End Paper Demos -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
